{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facebook Check-in Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading train.csv\n",
      "reading test.csv\n"
     ]
    }
   ],
   "source": [
    "#Starter code from Kaggle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "print 'reading train.csv'\n",
    "train = pd.read_csv('data/train.csv', nrows=5000)\n",
    "print 'reading test.csv'\n",
    "test = pd.read_csv('data/test.csv')\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'row_id', u'x', u'y', u'accuracy', u'time', u'place_id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'row_id', u'x', u'y', u'accuracy', u'time'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 10.0;\n",
    "\n",
    "x_step = 0.2\n",
    "y_step = 0.2\n",
    "\n",
    "x_ranges = zip(np.arange(0, size, x_step), np.arange(x_step, size + x_step, x_step));\n",
    "y_ranges = zip(np.arange(0, size, y_step), np.arange(y_step, size + y_step, y_step));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate hour, weekday, month and year for train and test\n"
     ]
    }
   ],
   "source": [
    "#Calculating individual time metrics from the time column\n",
    "print('Calculate hour, weekday, month and year for train and test')\n",
    "train['hour'] = (train['time']//60)%24+1 # 1 to 24\n",
    "train['weekday'] = (train['time']//1440)%7+1\n",
    "train['month'] = (train['time']//43200)%12+1 # rough estimate, month = 30 days\n",
    "train['year'] = (train['time']//525600)+1 \n",
    "\n",
    "test['hour'] = (test['time']//60)%24+1 # 1 to 24\n",
    "test['weekday'] = (test['time']//1440)%7+1\n",
    "test['month'] = (test['time']//43200)%12+1 # rough estimate, month = 30 days\n",
    "test['year'] = (test['time']//525600)+1\n",
    "\n",
    "X_train = train[['x','y','accuracy','time', 'hour', 'weekday', 'month', 'year']];\n",
    "y_train = train[['place_id']];\n",
    "X_test = test[['x','y','accuracy','time', 'hour', 'weekday', 'month', 'year']];\n",
    "X_test_labels = test[['row_id']];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'training classifier'\n",
    "clf = RandomForestClassifier(n_estimators = 10, n_jobs = -1,random_state=0)\n",
    "clf.fit(X_train.as_matrix(), y_train.as_matrix().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8607230, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating predictions\n",
      "An unexpected error occurred while tokenizing input file C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (724, 0))\n",
      "\n",
      "An unexpected error occurred while tokenizing input file C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (724, 0))\n",
      "\n",
      "An unexpected error occurred while tokenizing input file C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (724, 0))\n",
      "\n",
      "An unexpected error occurred while tokenizing input file C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (724, 0))\n",
      "\n",
      "An unexpected error occurred while tokenizing input file C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (724, 0))\n",
      "\n",
      "An unexpected error occurred while tokenizing input file C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (724, 0))\n",
      "\n",
      "An unexpected error occurred while tokenizing input file C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (724, 0))\n",
      "\n",
      "An unexpected error occurred while tokenizing input file C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (724, 0))\n",
      "\n",
      "An unexpected error occurred while tokenizing input file C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (724, 0))\n",
      "\n"
     ]
    },
    {
     "ename": "JoblibMemoryError",
     "evalue": "JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    157     pkg_name = mod_name.rpartition('.')[0]\n    158     main_globals = sys.modules[\"__main__\"].__dict__\n    159     if alter_argv:\n    160         sys.argv[0] = fname\n    161     return _run_code(code, main_globals, None,\n--> 162                      \"__main__\", fname, loader, pkg_name)\n        fname = r'C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    163 \n    164 def run_module(mod_name, init_globals=None,\n    165                run_name=None, alter_sys=False):\n    166     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\runpy.py in _run_code(code=<code object <module> at 00000000022D7E30, file ...lib\\site-packages\\ipykernel\\__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': r'C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from 'C:\\Users\\sch...conda\\lib\\site-packages\\ipykernel\\kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname=r'C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 00000000022D7E30, file ...lib\\site-packages\\ipykernel\\__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': r'C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from 'C:\\Users\\sch...conda\\lib\\site-packages\\ipykernel\\kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    591         \n    592         If a global instance already exists, this reinitializes and starts it\n    593         \"\"\"\n    594         app = cls.instance(**kwargs)\n    595         app.initialize(argv)\n--> 596         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    597 \n    598 #-----------------------------------------------------------------------------\n    599 # utility functions, for convenience\n    600 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    437         \n    438         if self.poller is not None:\n    439             self.poller.start()\n    440         self.kernel.start()\n    441         try:\n--> 442             ioloop.IOLoop.instance().start()\n    443         except KeyboardInterrupt:\n    444             pass\n    445 \n    446 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    878                 self._events.update(event_pairs)\n    879                 while self._events:\n    880                     fd, events = self._events.popitem()\n    881                     try:\n    882                         fd_obj, handler_func = self._handlers[fd]\n--> 883                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    884                     except (OSError, IOError) as e:\n    885                         if errno_from_exception(e) == errno.EPIPE:\n    886                             # Happens when the client closes the connection\n    887                             pass\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"print 'generating predictions'\\npreds = dict(z...int preds\\npreds = pd.DataFrame.from_dict(preds)\", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-20T15:35:55.340000', u'msg_id': u'1007CB68F2A9487187B8B17F3F876838', u'msg_type': u'execute_request', u'session': u'F4F79D98E09746A28EE44C03028A08EA', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'1007CB68F2A9487187B8B17F3F876838', 'msg_type': u'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['F4F79D98E09746A28EE44C03028A08EA']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"print 'generating predictions'\\npreds = dict(z...int preds\\npreds = pd.DataFrame.from_dict(preds)\", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-20T15:35:55.340000', u'msg_id': u'1007CB68F2A9487187B8B17F3F876838', u'msg_type': u'execute_request', u'session': u'F4F79D98E09746A28EE44C03028A08EA', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'1007CB68F2A9487187B8B17F3F876838', 'msg_type': u'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['F4F79D98E09746A28EE44C03028A08EA'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"print 'generating predictions'\\npreds = dict(z...int preds\\npreds = pd.DataFrame.from_dict(preds)\", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-20T15:35:55.340000', u'msg_id': u'1007CB68F2A9487187B8B17F3F876838', u'msg_type': u'execute_request', u'session': u'F4F79D98E09746A28EE44C03028A08EA', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'1007CB68F2A9487187B8B17F3F876838', 'msg_type': u'execute_request', 'parent_header': {}})\n    386         if not silent:\n    387             self.execution_count += 1\n    388             self._publish_execute_input(code, parent, self.execution_count)\n    389 \n    390         reply_content = self.do_execute(code, silent, store_history,\n--> 391                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    392 \n    393         # Flush output before sending the reply.\n    394         sys.stdout.flush()\n    395         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u\"print 'generating predictions'\\npreds = dict(z...int preds\\npreds = pd.DataFrame.from_dict(preds)\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    194 \n    195         reply_content = {}\n    196         # FIXME: the shell calls the exception handler itself.\n    197         shell._reply_content = None\n    198         try:\n--> 199             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u\"print 'generating predictions'\\npreds = dict(z...int preds\\npreds = pd.DataFrame.from_dict(preds)\"\n        store_history = True\n        silent = False\n    200         except:\n    201             status = u'error'\n    202             # FIXME: this code right now isn't being used yet by default,\n    203             # because the run_cell() call above directly fires off exception\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u\"print 'generating predictions'\\npreds = dict(z...int preds\\npreds = pd.DataFrame.from_dict(preds)\", store_history=True, silent=False, shell_futures=True)\n   2718                 self.displayhook.exec_result = result\n   2719 \n   2720                 # Execute the user code\n   2721                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2722                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2723                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2724 \n   2725                 # Reset this so later displayed values do not modify the\n   2726                 # ExecutionResult\n   2727                 self.displayhook.exec_result = None\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Print object>, <_ast.Assign object>, <_ast.Print object>, <_ast.Assign object>], cell_name='<ipython-input-8-bc89ce552500>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2820 \n   2821         try:\n   2822             for i, node in enumerate(to_run_exec):\n   2823                 mod = ast.Module([node])\n   2824                 code = compiler(mod, cell_name, \"exec\")\n-> 2825                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 000000000CDEF7B0, file \"<ipython-input-8-bc89ce552500>\", line 2>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   2826                     return True\n   2827 \n   2828             for i, node in enumerate(to_run_interactive):\n   2829                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 000000000CDEF7B0, file \"<ipython-input-8-bc89ce552500>\", line 2>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2880         outflag = 1  # happens in more places, so it's easier as default\n   2881         try:\n   2882             try:\n   2883                 self.hooks.pre_run_code_hook()\n   2884                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2885                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 000000000CDEF7B0, file \"<ipython-input-8-bc89ce552500>\", line 2>\n        self.user_global_ns = {'In': ['', u\"#Starter code from Kaggle\\n\\nimport pandas as ...d_csv('data/test.csv')\\nstart_time = time.time()\", u'print train.columns', u'print test.columns', u'size = 10.0;\\n\\nx_step = 0.2\\ny_step = 0.2\\n\\n...tep), np.arange(y_step, size + y_step, y_step));', u\"#Calculating individual time metrics from the ...h', 'year']];\\nX_test_labels = test[['row_id']];\", u'import sklearn\\nfrom sklearn.ensemble import RandomForestClassifier', u\"print 'training classifier'\\nclf = RandomFores..._train.as_matrix(), y_train.as_matrix().ravel())\", u\"print 'generating predictions'\\npreds = dict(z...int preds\\npreds = pd.DataFrame.from_dict(preds)\"], 'Out': {7: RandomForestClassifier(bootstrap=True, class_wei...lse, random_state=0, verbose=0, warm_start=False)}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'X_test':               x       y  accuracy     time  hour...       6      8     2\n\n[8607230 rows x 8 columns], 'X_test_labels':           row_id\n0              0\n1             ...7228\n8607229  8607229\n\n[8607230 rows x 1 columns], 'X_train':            x       y  accuracy    time  hour  we...20        7      1     1\n\n[5000 rows x 8 columns], '_': RandomForestClassifier(bootstrap=True, class_wei...lse, random_state=0, verbose=0, warm_start=False), '_7': RandomForestClassifier(bootstrap=True, class_wei...lse, random_state=0, verbose=0, warm_start=False), '__': '', '___': '', ...}\n        self.user_ns = {'In': ['', u\"#Starter code from Kaggle\\n\\nimport pandas as ...d_csv('data/test.csv')\\nstart_time = time.time()\", u'print train.columns', u'print test.columns', u'size = 10.0;\\n\\nx_step = 0.2\\ny_step = 0.2\\n\\n...tep), np.arange(y_step, size + y_step, y_step));', u\"#Calculating individual time metrics from the ...h', 'year']];\\nX_test_labels = test[['row_id']];\", u'import sklearn\\nfrom sklearn.ensemble import RandomForestClassifier', u\"print 'training classifier'\\nclf = RandomFores..._train.as_matrix(), y_train.as_matrix().ravel())\", u\"print 'generating predictions'\\npreds = dict(z...int preds\\npreds = pd.DataFrame.from_dict(preds)\"], 'Out': {7: RandomForestClassifier(bootstrap=True, class_wei...lse, random_state=0, verbose=0, warm_start=False)}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'X_test':               x       y  accuracy     time  hour...       6      8     2\n\n[8607230 rows x 8 columns], 'X_test_labels':           row_id\n0              0\n1             ...7228\n8607229  8607229\n\n[8607230 rows x 1 columns], 'X_train':            x       y  accuracy    time  hour  we...20        7      1     1\n\n[5000 rows x 8 columns], '_': RandomForestClassifier(bootstrap=True, class_wei...lse, random_state=0, verbose=0, warm_start=False), '_7': RandomForestClassifier(bootstrap=True, class_wei...lse, random_state=0, verbose=0, warm_start=False), '__': '', '___': '', ...}\n   2886             finally:\n   2887                 # Reset our crash handler in place\n   2888                 sys.excepthook = old_excepthook\n   2889         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\schiang\\Documents\\GitHub\\kaggle-facebook\\<ipython-input-8-bc89ce552500> in <module>()\n      1 \n----> 2 \n      3 \n      4 \n      5 print 'generating predictions'\n      6 preds = dict(zip([el for el in clf.classes_], zip(*clf.predict_proba(X_test.as_matrix()))))\n      7 print preds\n      8 preds = pd.DataFrame.from_dict(preds)\n      9 \n     10 \n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, class_wei...lse, random_state=0, verbose=0, warm_start=False), X=array([[   0.1675    ,    1.36080003,  107.     ...      8.        ,    2.        ]], dtype=float32))\n    542         # Parallel loop\n    543         all_proba = Parallel(n_jobs=n_jobs, verbose=self.verbose,\n    544                              backend=\"threading\")(\n    545             delayed(_parallel_helper)(e, 'predict_proba', X,\n    546                                       check_input=False)\n--> 547             for e in self.estimators_)\n        self.estimators_ = [DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=209652396, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=398764591, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=924231285, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1478610112, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=441365315, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1537364731, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=192771779, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1491434855, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1819583497, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=530702035, splitter='best')]\n    548 \n    549         # Reduce\n    550         proba = all_proba[0]\n    551 \n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=8), iterable=<generator object <genexpr>>)\n    805             if pre_dispatch == \"all\" or n_jobs == 1:\n    806                 # The iterable was consumed all at once by the above for loop.\n    807                 # No need to wait for async callbacks to trigger to\n    808                 # consumption.\n    809                 self._iterating = False\n--> 810             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=8)>\n    811             # Make sure that we get a last message telling us we are done\n    812             elapsed_time = time.time() - self._start_time\n    813             self._print('Done %3i out of %3i | elapsed: %s finished',\n    814                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Mon Jun 20 15:35:56 2016\nPID: 6460               Python 2.7.11: C:\\Users\\schiang\\Anaconda\\python.exe\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_helper>\n        args = (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=209652396, splitter='best'), 'predict_proba', array([[   0.1675    ,    1.36080003,  107.     ...      8.        ,    2.        ]], dtype=float32))\n        kwargs = {'check_input': False}\n        self.items = [(<function _parallel_helper>, (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=209652396, splitter='best'), 'predict_proba', array([[   0.1675    ,    1.36080003,  107.     ...      8.        ,    2.        ]], dtype=float32)), {'check_input': False})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py in _parallel_helper(obj=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=209652396, splitter='best'), methodname='predict_proba', *args=(array([[   0.1675    ,    1.36080003,  107.     ...      8.        ,    2.        ]], dtype=float32),), **kwargs={'check_input': False})\n    120     return tree\n    121 \n    122 \n    123 def _parallel_helper(obj, methodname, *args, **kwargs):\n    124     \"\"\"Private helper to workaround Python 2 pickle limitations\"\"\"\n--> 125     return getattr(obj, methodname)(*args, **kwargs)\n        obj = DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=209652396, splitter='best')\n        methodname = 'predict_proba'\n        args = (array([[   0.1675    ,    1.36080003,  107.     ...      8.        ,    2.        ]], dtype=float32),)\n        kwargs = {'check_input': False}\n    126 \n    127 \n    128 class BaseForest(six.with_metaclass(ABCMeta, BaseEnsemble,\n    129                                     _LearntSelectorMixin)):\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\tree.py in predict_proba(self=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=209652396, splitter='best'), X=array([[   0.1675    ,    1.36080003,  107.     ...      8.        ,    2.        ]], dtype=float32), check_input=False)\n    668             such arrays if n_outputs > 1.\n    669             The class probabilities of the input samples. The order of the\n    670             classes corresponds to that in the attribute `classes_`.\n    671         \"\"\"\n    672         X = self._validate_X_predict(X, check_input)\n--> 673         proba = self.tree_.predict(X)\n        proba = undefined\n        self.tree_.predict = <built-in method predict of sklearn.tree._tree.Tree object>\n        X = array([[   0.1675    ,    1.36080003,  107.     ...      8.        ,    2.        ]], dtype=float32)\n    674 \n    675         if self.n_outputs_ == 1:\n    676             proba = proba[:, :self.n_classes_]\n    677             normalizer = proba.sum(axis=1)[:, np.newaxis]\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd in sklearn.tree._tree.Tree.predict (sklearn\\tree\\_tree.c:8449)()\n    731 \n    732 \n    733 \n    734 \n    735 \n--> 736 \n    737 \n    738 \n    739 \n    740 \n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd in sklearn.tree._tree.Tree.predict (sklearn\\tree\\_tree.c:8321)()\n    733 \n    734 \n    735 \n    736 \n    737 \n--> 738 \n    739 \n    740 \n    741 \n    742 \n\nMemoryError: \n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJoblibMemoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-bc89ce552500>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'generating predictions'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    545\u001b[0m             delayed(_parallel_helper)(e, 'predict_proba', X,\n\u001b[0;32m    546\u001b[0m                                       check_input=False)\n\u001b[1;32m--> 547\u001b[1;33m             for e in self.estimators_)\n\u001b[0m\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;31m# Reduce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[1;31m# a working pool as they expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibMemoryError\u001b[0m: JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    157     pkg_name = mod_name.rpartition('.')[0]\n    158     main_globals = sys.modules[\"__main__\"].__dict__\n    159     if alter_argv:\n    160         sys.argv[0] = fname\n    161     return _run_code(code, main_globals, None,\n--> 162                      \"__main__\", fname, loader, pkg_name)\n        fname = r'C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    163 \n    164 def run_module(mod_name, init_globals=None,\n    165                run_name=None, alter_sys=False):\n    166     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\runpy.py in _run_code(code=<code object <module> at 00000000022D7E30, file ...lib\\site-packages\\ipykernel\\__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': r'C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from 'C:\\Users\\sch...conda\\lib\\site-packages\\ipykernel\\kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname=r'C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 00000000022D7E30, file ...lib\\site-packages\\ipykernel\\__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': r'C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from 'C:\\Users\\sch...conda\\lib\\site-packages\\ipykernel\\kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    591         \n    592         If a global instance already exists, this reinitializes and starts it\n    593         \"\"\"\n    594         app = cls.instance(**kwargs)\n    595         app.initialize(argv)\n--> 596         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    597 \n    598 #-----------------------------------------------------------------------------\n    599 # utility functions, for convenience\n    600 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    437         \n    438         if self.poller is not None:\n    439             self.poller.start()\n    440         self.kernel.start()\n    441         try:\n--> 442             ioloop.IOLoop.instance().start()\n    443         except KeyboardInterrupt:\n    444             pass\n    445 \n    446 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    878                 self._events.update(event_pairs)\n    879                 while self._events:\n    880                     fd, events = self._events.popitem()\n    881                     try:\n    882                         fd_obj, handler_func = self._handlers[fd]\n--> 883                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    884                     except (OSError, IOError) as e:\n    885                         if errno_from_exception(e) == errno.EPIPE:\n    886                             # Happens when the client closes the connection\n    887                             pass\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"print 'generating predictions'\\npreds = dict(z...int preds\\npreds = pd.DataFrame.from_dict(preds)\", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-20T15:35:55.340000', u'msg_id': u'1007CB68F2A9487187B8B17F3F876838', u'msg_type': u'execute_request', u'session': u'F4F79D98E09746A28EE44C03028A08EA', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'1007CB68F2A9487187B8B17F3F876838', 'msg_type': u'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['F4F79D98E09746A28EE44C03028A08EA']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"print 'generating predictions'\\npreds = dict(z...int preds\\npreds = pd.DataFrame.from_dict(preds)\", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-20T15:35:55.340000', u'msg_id': u'1007CB68F2A9487187B8B17F3F876838', u'msg_type': u'execute_request', u'session': u'F4F79D98E09746A28EE44C03028A08EA', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'1007CB68F2A9487187B8B17F3F876838', 'msg_type': u'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['F4F79D98E09746A28EE44C03028A08EA'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"print 'generating predictions'\\npreds = dict(z...int preds\\npreds = pd.DataFrame.from_dict(preds)\", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-20T15:35:55.340000', u'msg_id': u'1007CB68F2A9487187B8B17F3F876838', u'msg_type': u'execute_request', u'session': u'F4F79D98E09746A28EE44C03028A08EA', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'1007CB68F2A9487187B8B17F3F876838', 'msg_type': u'execute_request', 'parent_header': {}})\n    386         if not silent:\n    387             self.execution_count += 1\n    388             self._publish_execute_input(code, parent, self.execution_count)\n    389 \n    390         reply_content = self.do_execute(code, silent, store_history,\n--> 391                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    392 \n    393         # Flush output before sending the reply.\n    394         sys.stdout.flush()\n    395         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u\"print 'generating predictions'\\npreds = dict(z...int preds\\npreds = pd.DataFrame.from_dict(preds)\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    194 \n    195         reply_content = {}\n    196         # FIXME: the shell calls the exception handler itself.\n    197         shell._reply_content = None\n    198         try:\n--> 199             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u\"print 'generating predictions'\\npreds = dict(z...int preds\\npreds = pd.DataFrame.from_dict(preds)\"\n        store_history = True\n        silent = False\n    200         except:\n    201             status = u'error'\n    202             # FIXME: this code right now isn't being used yet by default,\n    203             # because the run_cell() call above directly fires off exception\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u\"print 'generating predictions'\\npreds = dict(z...int preds\\npreds = pd.DataFrame.from_dict(preds)\", store_history=True, silent=False, shell_futures=True)\n   2718                 self.displayhook.exec_result = result\n   2719 \n   2720                 # Execute the user code\n   2721                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2722                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2723                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2724 \n   2725                 # Reset this so later displayed values do not modify the\n   2726                 # ExecutionResult\n   2727                 self.displayhook.exec_result = None\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Print object>, <_ast.Assign object>, <_ast.Print object>, <_ast.Assign object>], cell_name='<ipython-input-8-bc89ce552500>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2820 \n   2821         try:\n   2822             for i, node in enumerate(to_run_exec):\n   2823                 mod = ast.Module([node])\n   2824                 code = compiler(mod, cell_name, \"exec\")\n-> 2825                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 000000000CDEF7B0, file \"<ipython-input-8-bc89ce552500>\", line 2>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   2826                     return True\n   2827 \n   2828             for i, node in enumerate(to_run_interactive):\n   2829                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 000000000CDEF7B0, file \"<ipython-input-8-bc89ce552500>\", line 2>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2880         outflag = 1  # happens in more places, so it's easier as default\n   2881         try:\n   2882             try:\n   2883                 self.hooks.pre_run_code_hook()\n   2884                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2885                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 000000000CDEF7B0, file \"<ipython-input-8-bc89ce552500>\", line 2>\n        self.user_global_ns = {'In': ['', u\"#Starter code from Kaggle\\n\\nimport pandas as ...d_csv('data/test.csv')\\nstart_time = time.time()\", u'print train.columns', u'print test.columns', u'size = 10.0;\\n\\nx_step = 0.2\\ny_step = 0.2\\n\\n...tep), np.arange(y_step, size + y_step, y_step));', u\"#Calculating individual time metrics from the ...h', 'year']];\\nX_test_labels = test[['row_id']];\", u'import sklearn\\nfrom sklearn.ensemble import RandomForestClassifier', u\"print 'training classifier'\\nclf = RandomFores..._train.as_matrix(), y_train.as_matrix().ravel())\", u\"print 'generating predictions'\\npreds = dict(z...int preds\\npreds = pd.DataFrame.from_dict(preds)\"], 'Out': {7: RandomForestClassifier(bootstrap=True, class_wei...lse, random_state=0, verbose=0, warm_start=False)}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'X_test':               x       y  accuracy     time  hour...       6      8     2\n\n[8607230 rows x 8 columns], 'X_test_labels':           row_id\n0              0\n1             ...7228\n8607229  8607229\n\n[8607230 rows x 1 columns], 'X_train':            x       y  accuracy    time  hour  we...20        7      1     1\n\n[5000 rows x 8 columns], '_': RandomForestClassifier(bootstrap=True, class_wei...lse, random_state=0, verbose=0, warm_start=False), '_7': RandomForestClassifier(bootstrap=True, class_wei...lse, random_state=0, verbose=0, warm_start=False), '__': '', '___': '', ...}\n        self.user_ns = {'In': ['', u\"#Starter code from Kaggle\\n\\nimport pandas as ...d_csv('data/test.csv')\\nstart_time = time.time()\", u'print train.columns', u'print test.columns', u'size = 10.0;\\n\\nx_step = 0.2\\ny_step = 0.2\\n\\n...tep), np.arange(y_step, size + y_step, y_step));', u\"#Calculating individual time metrics from the ...h', 'year']];\\nX_test_labels = test[['row_id']];\", u'import sklearn\\nfrom sklearn.ensemble import RandomForestClassifier', u\"print 'training classifier'\\nclf = RandomFores..._train.as_matrix(), y_train.as_matrix().ravel())\", u\"print 'generating predictions'\\npreds = dict(z...int preds\\npreds = pd.DataFrame.from_dict(preds)\"], 'Out': {7: RandomForestClassifier(bootstrap=True, class_wei...lse, random_state=0, verbose=0, warm_start=False)}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'X_test':               x       y  accuracy     time  hour...       6      8     2\n\n[8607230 rows x 8 columns], 'X_test_labels':           row_id\n0              0\n1             ...7228\n8607229  8607229\n\n[8607230 rows x 1 columns], 'X_train':            x       y  accuracy    time  hour  we...20        7      1     1\n\n[5000 rows x 8 columns], '_': RandomForestClassifier(bootstrap=True, class_wei...lse, random_state=0, verbose=0, warm_start=False), '_7': RandomForestClassifier(bootstrap=True, class_wei...lse, random_state=0, verbose=0, warm_start=False), '__': '', '___': '', ...}\n   2886             finally:\n   2887                 # Reset our crash handler in place\n   2888                 sys.excepthook = old_excepthook\n   2889         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\schiang\\Documents\\GitHub\\kaggle-facebook\\<ipython-input-8-bc89ce552500> in <module>()\n      1 \n----> 2 \n      3 \n      4 \n      5 print 'generating predictions'\n      6 preds = dict(zip([el for el in clf.classes_], zip(*clf.predict_proba(X_test.as_matrix()))))\n      7 print preds\n      8 preds = pd.DataFrame.from_dict(preds)\n      9 \n     10 \n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, class_wei...lse, random_state=0, verbose=0, warm_start=False), X=array([[   0.1675    ,    1.36080003,  107.     ...      8.        ,    2.        ]], dtype=float32))\n    542         # Parallel loop\n    543         all_proba = Parallel(n_jobs=n_jobs, verbose=self.verbose,\n    544                              backend=\"threading\")(\n    545             delayed(_parallel_helper)(e, 'predict_proba', X,\n    546                                       check_input=False)\n--> 547             for e in self.estimators_)\n        self.estimators_ = [DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=209652396, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=398764591, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=924231285, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1478610112, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=441365315, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1537364731, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=192771779, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1491434855, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1819583497, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=530702035, splitter='best')]\n    548 \n    549         # Reduce\n    550         proba = all_proba[0]\n    551 \n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=8), iterable=<generator object <genexpr>>)\n    805             if pre_dispatch == \"all\" or n_jobs == 1:\n    806                 # The iterable was consumed all at once by the above for loop.\n    807                 # No need to wait for async callbacks to trigger to\n    808                 # consumption.\n    809                 self._iterating = False\n--> 810             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=8)>\n    811             # Make sure that we get a last message telling us we are done\n    812             elapsed_time = time.time() - self._start_time\n    813             self._print('Done %3i out of %3i | elapsed: %s finished',\n    814                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Mon Jun 20 15:35:56 2016\nPID: 6460               Python 2.7.11: C:\\Users\\schiang\\Anaconda\\python.exe\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_helper>\n        args = (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=209652396, splitter='best'), 'predict_proba', array([[   0.1675    ,    1.36080003,  107.     ...      8.        ,    2.        ]], dtype=float32))\n        kwargs = {'check_input': False}\n        self.items = [(<function _parallel_helper>, (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=209652396, splitter='best'), 'predict_proba', array([[   0.1675    ,    1.36080003,  107.     ...      8.        ,    2.        ]], dtype=float32)), {'check_input': False})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py in _parallel_helper(obj=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=209652396, splitter='best'), methodname='predict_proba', *args=(array([[   0.1675    ,    1.36080003,  107.     ...      8.        ,    2.        ]], dtype=float32),), **kwargs={'check_input': False})\n    120     return tree\n    121 \n    122 \n    123 def _parallel_helper(obj, methodname, *args, **kwargs):\n    124     \"\"\"Private helper to workaround Python 2 pickle limitations\"\"\"\n--> 125     return getattr(obj, methodname)(*args, **kwargs)\n        obj = DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=209652396, splitter='best')\n        methodname = 'predict_proba'\n        args = (array([[   0.1675    ,    1.36080003,  107.     ...      8.        ,    2.        ]], dtype=float32),)\n        kwargs = {'check_input': False}\n    126 \n    127 \n    128 class BaseForest(six.with_metaclass(ABCMeta, BaseEnsemble,\n    129                                     _LearntSelectorMixin)):\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\tree.py in predict_proba(self=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=209652396, splitter='best'), X=array([[   0.1675    ,    1.36080003,  107.     ...      8.        ,    2.        ]], dtype=float32), check_input=False)\n    668             such arrays if n_outputs > 1.\n    669             The class probabilities of the input samples. The order of the\n    670             classes corresponds to that in the attribute `classes_`.\n    671         \"\"\"\n    672         X = self._validate_X_predict(X, check_input)\n--> 673         proba = self.tree_.predict(X)\n        proba = undefined\n        self.tree_.predict = <built-in method predict of sklearn.tree._tree.Tree object>\n        X = array([[   0.1675    ,    1.36080003,  107.     ...      8.        ,    2.        ]], dtype=float32)\n    674 \n    675         if self.n_outputs_ == 1:\n    676             proba = proba[:, :self.n_classes_]\n    677             normalizer = proba.sum(axis=1)[:, np.newaxis]\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd in sklearn.tree._tree.Tree.predict (sklearn\\tree\\_tree.c:8449)()\n    731 \n    732 \n    733 \n    734 \n    735 \n--> 736 \n    737 \n    738 \n    739 \n    740 \n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd in sklearn.tree._tree.Tree.predict (sklearn\\tree\\_tree.c:8321)()\n    733 \n    734 \n    735 \n    736 \n    737 \n--> 738 \n    739 \n    740 \n    741 \n    742 \n\nMemoryError: \n___________________________________________________________________________"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred while tokenizing input file C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (724, 0))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'generating predictions'\n",
    "preds = dict(zip([el for el in clf.classes_], zip(*clf.predict_proba(X_test.as_matrix()))))\n",
    "print preds\n",
    "preds = pd.DataFrame.from_dict(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training classifier\n",
      "generating predictions\n",
      "An unexpected error occurred while tokenizing input file C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (725, 0))\n",
      "\n",
      "An unexpected error occurred while tokenizing input file C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (725, 0))\n",
      "\n",
      "An unexpected error occurred while tokenizing input file C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (725, 0))\n",
      "\n",
      "An unexpected error occurred while tokenizing input file C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (725, 0))\n",
      "\n",
      "An unexpected error occurred while tokenizing input file C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (725, 0))\n",
      "\n",
      "An unexpected error occurred while tokenizing input file C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (725, 0))\n",
      "\n",
      "An unexpected error occurred while tokenizing input file C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (725, 0))\n",
      "\n",
      "An unexpected error occurred while tokenizing input file C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (725, 0))\n",
      "\n"
     ]
    },
    {
     "ename": "JoblibMemoryError",
     "evalue": "JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    157     pkg_name = mod_name.rpartition('.')[0]\n    158     main_globals = sys.modules[\"__main__\"].__dict__\n    159     if alter_argv:\n    160         sys.argv[0] = fname\n    161     return _run_code(code, main_globals, None,\n--> 162                      \"__main__\", fname, loader, pkg_name)\n        fname = r'C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    163 \n    164 def run_module(mod_name, init_globals=None,\n    165                run_name=None, alter_sys=False):\n    166     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\runpy.py in _run_code(code=<code object <module> at 0000000002207E30, file ...lib\\site-packages\\ipykernel\\__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': r'C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from 'C:\\Users\\sch...conda\\lib\\site-packages\\ipykernel\\kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname=r'C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0000000002207E30, file ...lib\\site-packages\\ipykernel\\__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': r'C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from 'C:\\Users\\sch...conda\\lib\\site-packages\\ipykernel\\kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    591         \n    592         If a global instance already exists, this reinitializes and starts it\n    593         \"\"\"\n    594         app = cls.instance(**kwargs)\n    595         app.initialize(argv)\n--> 596         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    597 \n    598 #-----------------------------------------------------------------------------\n    599 # utility functions, for convenience\n    600 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    437         \n    438         if self.poller is not None:\n    439             self.poller.start()\n    440         self.kernel.start()\n    441         try:\n--> 442             ioloop.IOLoop.instance().start()\n    443         except KeyboardInterrupt:\n    444             pass\n    445 \n    446 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    878                 self._events.update(event_pairs)\n    879                 while self._events:\n    880                     fd, events = self._events.popitem()\n    881                     try:\n    882                         fd_obj, handler_func = self._handlers[fd]\n--> 883                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    884                     except (OSError, IOError) as e:\n    885                         if errno_from_exception(e) == errno.EPIPE:\n    886                             # Happens when the client closes the connection\n    887                             pass\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-20T14:36:36.932000', u'msg_id': u'2C1741159DF740C48C326B50C982ACFC', u'msg_type': u'execute_request', u'session': u'42337D6D71114E5287D555ACA2BBC6F6', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'2C1741159DF740C48C326B50C982ACFC', 'msg_type': u'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['42337D6D71114E5287D555ACA2BBC6F6']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-20T14:36:36.932000', u'msg_id': u'2C1741159DF740C48C326B50C982ACFC', u'msg_type': u'execute_request', u'session': u'42337D6D71114E5287D555ACA2BBC6F6', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'2C1741159DF740C48C326B50C982ACFC', 'msg_type': u'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['42337D6D71114E5287D555ACA2BBC6F6'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-20T14:36:36.932000', u'msg_id': u'2C1741159DF740C48C326B50C982ACFC', u'msg_type': u'execute_request', u'session': u'42337D6D71114E5287D555ACA2BBC6F6', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'2C1741159DF740C48C326B50C982ACFC', 'msg_type': u'execute_request', 'parent_header': {}})\n    386         if not silent:\n    387             self.execution_count += 1\n    388             self._publish_execute_input(code, parent, self.execution_count)\n    389 \n    390         reply_content = self.do_execute(code, silent, store_history,\n--> 391                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    392 \n    393         # Flush output before sending the reply.\n    394         sys.stdout.flush()\n    395         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    194 \n    195         reply_content = {}\n    196         # FIXME: the shell calls the exception handler itself.\n    197         shell._reply_content = None\n    198         try:\n--> 199             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\''\n        store_history = True\n        silent = False\n    200         except:\n    201             status = u'error'\n    202             # FIXME: this code right now isn't being used yet by default,\n    203             # because the run_cell() call above directly fires off exception\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', store_history=True, silent=False, shell_futures=True)\n   2718                 self.displayhook.exec_result = result\n   2719 \n   2720                 # Execute the user code\n   2721                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2722                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2723                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2724 \n   2725                 # Reset this so later displayed values do not modify the\n   2726                 # ExecutionResult\n   2727                 self.displayhook.exec_result = None\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Print object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Print object>, <_ast.Assign object>, <_ast.Print object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Print object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Print object>], cell_name='<ipython-input-13-1066e963442e>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2820 \n   2821         try:\n   2822             for i, node in enumerate(to_run_exec):\n   2823                 mod = ast.Module([node])\n   2824                 code = compiler(mod, cell_name, \"exec\")\n-> 2825                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 00000000092FF330, file \"<ipython-input-13-1066e963442e>\", line 6>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   2826                     return True\n   2827 \n   2828             for i, node in enumerate(to_run_interactive):\n   2829                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 00000000092FF330, file \"<ipython-input-13-1066e963442e>\", line 6>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2880         outflag = 1  # happens in more places, so it's easier as default\n   2881         try:\n   2882             try:\n   2883                 self.hooks.pre_run_code_hook()\n   2884                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2885                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 00000000092FF330, file \"<ipython-input-13-1066e963442e>\", line 6>\n        self.user_global_ns = {'In': ['', u\"#Starter code from Kaggle\\n\\nimport pandas as ...d_csv('data/test.csv')\\nstart_time = time.time()\", u'print train.columns', u'print test.columns', u'size = 10.0;\\n\\nx_step = 0.2\\ny_step = 0.2\\n\\n...tep), np.arange(y_step, size + y_step, y_step));', u\"#Calculating individual time metrics from the ...h', 'year']];\\nX_test_labels = test[['row_id']];\", u'from sklearn.ensemble import RandomForestClassifier', u'X_train.shape', u'y_train.shape', u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\''], 'Out': {7: (1000, 8), 8: (1000, 1)}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'X_test':               x       y  accuracy     time  hour...       6      8     2\n\n[8607230 rows x 8 columns], 'X_test_labels':           row_id\n0              0\n1             ...7228\n8607229  8607229\n\n[8607230 rows x 1 columns], 'X_train':           x       y  accuracy    time  hour  wee...10        5      3     1\n\n[1000 rows x 8 columns], '_': (1000, 1), '_7': (1000, 8), '_8': (1000, 1), '__': (1000, 8), ...}\n        self.user_ns = {'In': ['', u\"#Starter code from Kaggle\\n\\nimport pandas as ...d_csv('data/test.csv')\\nstart_time = time.time()\", u'print train.columns', u'print test.columns', u'size = 10.0;\\n\\nx_step = 0.2\\ny_step = 0.2\\n\\n...tep), np.arange(y_step, size + y_step, y_step));', u\"#Calculating individual time metrics from the ...h', 'year']];\\nX_test_labels = test[['row_id']];\", u'from sklearn.ensemble import RandomForestClassifier', u'X_train.shape', u'y_train.shape', u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\''], 'Out': {7: (1000, 8), 8: (1000, 1)}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'X_test':               x       y  accuracy     time  hour...       6      8     2\n\n[8607230 rows x 8 columns], 'X_test_labels':           row_id\n0              0\n1             ...7228\n8607229  8607229\n\n[8607230 rows x 1 columns], 'X_train':           x       y  accuracy    time  hour  wee...10        5      3     1\n\n[1000 rows x 8 columns], '_': (1000, 1), '_7': (1000, 8), '_8': (1000, 1), '__': (1000, 8), ...}\n   2886             finally:\n   2887                 # Reset our crash handler in place\n   2888                 sys.excepthook = old_excepthook\n   2889         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\schiang\\Documents\\GitHub\\kaggle-facebook\\<ipython-input-13-1066e963442e> in <module>()\n      1 print 'training classifier'\n      2 clf = RandomForestClassifier(n_estimators = 10, n_jobs = -1,random_state=0)\n      3 clf.fit(X_train, y_train.as_matrix().ravel())\n      4 \n      5 print 'generating predictions'\n----> 6 preds = dict(zip([el for el in clf.classes_], zip(*clf.predict_proba(X_test))))\n      7 print preds\n      8 preds = pd.DataFrame.from_dict(preds)\n      9 \n     10 preds['0_'], preds['1_'], preds['2_'] = zip(*preds.apply(lambda x: preds.columns[x.argsort()[::-1][:3]].tolist(), axis=1));\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, class_wei...lse, random_state=0, verbose=0, warm_start=False), X=array([[  0.1675,   1.3608, ...,  10.    ,   2. ...7.8736, ...,   8.    ,   2.    ]], dtype=float32))\n    542         # Parallel loop\n    543         all_proba = Parallel(n_jobs=n_jobs, verbose=self.verbose,\n    544                              backend=\"threading\")(\n    545             delayed(_parallel_helper)(e, 'predict_proba', X,\n    546                                       check_input=False)\n--> 547             for e in self.estimators_)\n        self.estimators_ = [DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=209652396, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=398764591, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=924231285, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1478610112, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=441365315, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1537364731, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=192771779, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1491434855, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1819583497, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=530702035, splitter='best')]\n    548 \n    549         # Reduce\n    550         proba = all_proba[0]\n    551 \n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=8), iterable=<generator object <genexpr>>)\n    807             if pre_dispatch == \"all\" or n_jobs == 1:\n    808                 # The iterable was consumed all at once by the above for loop.\n    809                 # No need to wait for async callbacks to trigger to\n    810                 # consumption.\n    811                 self._iterating = False\n--> 812             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=8)>\n    813             # Make sure that we get a last message telling us we are done\n    814             elapsed_time = time.time() - self._start_time\n    815             self._print('Done %3i out of %3i | elapsed: %s finished',\n    816                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Mon Jun 20 14:36:37 2016\nPID: 4956               Python 2.7.11: C:\\Users\\schiang\\Anaconda\\python.exe\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.pyc in _parallel_helper(obj=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=209652396, splitter='best'), methodname='predict_proba', *args=(array([[  0.1675,   1.3608, ...,  10.    ,   2. ...7.8736, ...,   8.    ,   2.    ]], dtype=float32),), **kwargs={'check_input': False})\n    120     return tree\n    121 \n    122 \n    123 def _parallel_helper(obj, methodname, *args, **kwargs):\n    124     \"\"\"Private helper to workaround Python 2 pickle limitations\"\"\"\n--> 125     return getattr(obj, methodname)(*args, **kwargs)\n    126 \n    127 \n    128 class BaseForest(six.with_metaclass(ABCMeta, BaseEnsemble,\n    129                                     _LearntSelectorMixin)):\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\tree.pyc in predict_proba(self=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=209652396, splitter='best'), X=array([[  0.1675,   1.3608, ...,  10.    ,   2. ...7.8736, ...,   8.    ,   2.    ]], dtype=float32), check_input=False)\n    668             such arrays if n_outputs > 1.\n    669             The class probabilities of the input samples. The order of the\n    670             classes corresponds to that in the attribute `classes_`.\n    671         \"\"\"\n    672         X = self._validate_X_predict(X, check_input)\n--> 673         proba = self.tree_.predict(X)\n    674 \n    675         if self.n_outputs_ == 1:\n    676             proba = proba[:, :self.n_classes_]\n    677             normalizer = proba.sum(axis=1)[:, np.newaxis]\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd in sklearn.tree._tree.Tree.predict (sklearn\\tree\\_tree.c:8449)()\n    731 \n    732 \n    733 \n    734 \n    735 \n--> 736 \n    737 \n    738 \n    739 \n    740 \n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd in sklearn.tree._tree.Tree.predict (sklearn\\tree\\_tree.c:8321)()\n    733 \n    734 \n    735 \n    736 \n    737 \n--> 738 \n    739 \n    740 \n    741 \n    742 \n\nMemoryError: \n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJoblibMemoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-1066e963442e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'generating predictions'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    545\u001b[0m             delayed(_parallel_helper)(e, 'predict_proba', X,\n\u001b[0;32m    546\u001b[0m                                       check_input=False)\n\u001b[1;32m--> 547\u001b[1;33m             for e in self.estimators_)\n\u001b[0m\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;31m# Reduce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    810\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    760\u001b[0m                         \u001b[1;31m# a working pool as they expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibMemoryError\u001b[0m: JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    157     pkg_name = mod_name.rpartition('.')[0]\n    158     main_globals = sys.modules[\"__main__\"].__dict__\n    159     if alter_argv:\n    160         sys.argv[0] = fname\n    161     return _run_code(code, main_globals, None,\n--> 162                      \"__main__\", fname, loader, pkg_name)\n        fname = r'C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    163 \n    164 def run_module(mod_name, init_globals=None,\n    165                run_name=None, alter_sys=False):\n    166     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\runpy.py in _run_code(code=<code object <module> at 0000000002207E30, file ...lib\\site-packages\\ipykernel\\__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': r'C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from 'C:\\Users\\sch...conda\\lib\\site-packages\\ipykernel\\kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname=r'C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0000000002207E30, file ...lib\\site-packages\\ipykernel\\__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': r'C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from 'C:\\Users\\sch...conda\\lib\\site-packages\\ipykernel\\kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    591         \n    592         If a global instance already exists, this reinitializes and starts it\n    593         \"\"\"\n    594         app = cls.instance(**kwargs)\n    595         app.initialize(argv)\n--> 596         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    597 \n    598 #-----------------------------------------------------------------------------\n    599 # utility functions, for convenience\n    600 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    437         \n    438         if self.poller is not None:\n    439             self.poller.start()\n    440         self.kernel.start()\n    441         try:\n--> 442             ioloop.IOLoop.instance().start()\n    443         except KeyboardInterrupt:\n    444             pass\n    445 \n    446 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    878                 self._events.update(event_pairs)\n    879                 while self._events:\n    880                     fd, events = self._events.popitem()\n    881                     try:\n    882                         fd_obj, handler_func = self._handlers[fd]\n--> 883                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    884                     except (OSError, IOError) as e:\n    885                         if errno_from_exception(e) == errno.EPIPE:\n    886                             # Happens when the client closes the connection\n    887                             pass\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-20T14:36:36.932000', u'msg_id': u'2C1741159DF740C48C326B50C982ACFC', u'msg_type': u'execute_request', u'session': u'42337D6D71114E5287D555ACA2BBC6F6', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'2C1741159DF740C48C326B50C982ACFC', 'msg_type': u'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['42337D6D71114E5287D555ACA2BBC6F6']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-20T14:36:36.932000', u'msg_id': u'2C1741159DF740C48C326B50C982ACFC', u'msg_type': u'execute_request', u'session': u'42337D6D71114E5287D555ACA2BBC6F6', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'2C1741159DF740C48C326B50C982ACFC', 'msg_type': u'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['42337D6D71114E5287D555ACA2BBC6F6'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-20T14:36:36.932000', u'msg_id': u'2C1741159DF740C48C326B50C982ACFC', u'msg_type': u'execute_request', u'session': u'42337D6D71114E5287D555ACA2BBC6F6', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'2C1741159DF740C48C326B50C982ACFC', 'msg_type': u'execute_request', 'parent_header': {}})\n    386         if not silent:\n    387             self.execution_count += 1\n    388             self._publish_execute_input(code, parent, self.execution_count)\n    389 \n    390         reply_content = self.do_execute(code, silent, store_history,\n--> 391                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    392 \n    393         # Flush output before sending the reply.\n    394         sys.stdout.flush()\n    395         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    194 \n    195         reply_content = {}\n    196         # FIXME: the shell calls the exception handler itself.\n    197         shell._reply_content = None\n    198         try:\n--> 199             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\''\n        store_history = True\n        silent = False\n    200         except:\n    201             status = u'error'\n    202             # FIXME: this code right now isn't being used yet by default,\n    203             # because the run_cell() call above directly fires off exception\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', store_history=True, silent=False, shell_futures=True)\n   2718                 self.displayhook.exec_result = result\n   2719 \n   2720                 # Execute the user code\n   2721                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2722                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2723                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2724 \n   2725                 # Reset this so later displayed values do not modify the\n   2726                 # ExecutionResult\n   2727                 self.displayhook.exec_result = None\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Print object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Print object>, <_ast.Assign object>, <_ast.Print object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Print object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Print object>], cell_name='<ipython-input-13-1066e963442e>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2820 \n   2821         try:\n   2822             for i, node in enumerate(to_run_exec):\n   2823                 mod = ast.Module([node])\n   2824                 code = compiler(mod, cell_name, \"exec\")\n-> 2825                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 00000000092FF330, file \"<ipython-input-13-1066e963442e>\", line 6>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   2826                     return True\n   2827 \n   2828             for i, node in enumerate(to_run_interactive):\n   2829                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 00000000092FF330, file \"<ipython-input-13-1066e963442e>\", line 6>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2880         outflag = 1  # happens in more places, so it's easier as default\n   2881         try:\n   2882             try:\n   2883                 self.hooks.pre_run_code_hook()\n   2884                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2885                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 00000000092FF330, file \"<ipython-input-13-1066e963442e>\", line 6>\n        self.user_global_ns = {'In': ['', u\"#Starter code from Kaggle\\n\\nimport pandas as ...d_csv('data/test.csv')\\nstart_time = time.time()\", u'print train.columns', u'print test.columns', u'size = 10.0;\\n\\nx_step = 0.2\\ny_step = 0.2\\n\\n...tep), np.arange(y_step, size + y_step, y_step));', u\"#Calculating individual time metrics from the ...h', 'year']];\\nX_test_labels = test[['row_id']];\", u'from sklearn.ensemble import RandomForestClassifier', u'X_train.shape', u'y_train.shape', u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\''], 'Out': {7: (1000, 8), 8: (1000, 1)}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'X_test':               x       y  accuracy     time  hour...       6      8     2\n\n[8607230 rows x 8 columns], 'X_test_labels':           row_id\n0              0\n1             ...7228\n8607229  8607229\n\n[8607230 rows x 1 columns], 'X_train':           x       y  accuracy    time  hour  wee...10        5      3     1\n\n[1000 rows x 8 columns], '_': (1000, 1), '_7': (1000, 8), '_8': (1000, 1), '__': (1000, 8), ...}\n        self.user_ns = {'In': ['', u\"#Starter code from Kaggle\\n\\nimport pandas as ...d_csv('data/test.csv')\\nstart_time = time.time()\", u'print train.columns', u'print test.columns', u'size = 10.0;\\n\\nx_step = 0.2\\ny_step = 0.2\\n\\n...tep), np.arange(y_step, size + y_step, y_step));', u\"#Calculating individual time metrics from the ...h', 'year']];\\nX_test_labels = test[['row_id']];\", u'from sklearn.ensemble import RandomForestClassifier', u'X_train.shape', u'y_train.shape', u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\'', u'print \\'training classifier\\'\\nclf = RandomFor...to_csv(sub_file,index=False)\\nprint \\'finished\\''], 'Out': {7: (1000, 8), 8: (1000, 1)}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'X_test':               x       y  accuracy     time  hour...       6      8     2\n\n[8607230 rows x 8 columns], 'X_test_labels':           row_id\n0              0\n1             ...7228\n8607229  8607229\n\n[8607230 rows x 1 columns], 'X_train':           x       y  accuracy    time  hour  wee...10        5      3     1\n\n[1000 rows x 8 columns], '_': (1000, 1), '_7': (1000, 8), '_8': (1000, 1), '__': (1000, 8), ...}\n   2886             finally:\n   2887                 # Reset our crash handler in place\n   2888                 sys.excepthook = old_excepthook\n   2889         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\schiang\\Documents\\GitHub\\kaggle-facebook\\<ipython-input-13-1066e963442e> in <module>()\n      1 print 'training classifier'\n      2 clf = RandomForestClassifier(n_estimators = 10, n_jobs = -1,random_state=0)\n      3 clf.fit(X_train, y_train.as_matrix().ravel())\n      4 \n      5 print 'generating predictions'\n----> 6 preds = dict(zip([el for el in clf.classes_], zip(*clf.predict_proba(X_test))))\n      7 print preds\n      8 preds = pd.DataFrame.from_dict(preds)\n      9 \n     10 preds['0_'], preds['1_'], preds['2_'] = zip(*preds.apply(lambda x: preds.columns[x.argsort()[::-1][:3]].tolist(), axis=1));\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, class_wei...lse, random_state=0, verbose=0, warm_start=False), X=array([[  0.1675,   1.3608, ...,  10.    ,   2. ...7.8736, ...,   8.    ,   2.    ]], dtype=float32))\n    542         # Parallel loop\n    543         all_proba = Parallel(n_jobs=n_jobs, verbose=self.verbose,\n    544                              backend=\"threading\")(\n    545             delayed(_parallel_helper)(e, 'predict_proba', X,\n    546                                       check_input=False)\n--> 547             for e in self.estimators_)\n        self.estimators_ = [DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=209652396, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=398764591, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=924231285, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1478610112, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=441365315, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1537364731, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=192771779, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1491434855, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1819583497, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=530702035, splitter='best')]\n    548 \n    549         # Reduce\n    550         proba = all_proba[0]\n    551 \n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=8), iterable=<generator object <genexpr>>)\n    807             if pre_dispatch == \"all\" or n_jobs == 1:\n    808                 # The iterable was consumed all at once by the above for loop.\n    809                 # No need to wait for async callbacks to trigger to\n    810                 # consumption.\n    811                 self._iterating = False\n--> 812             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=8)>\n    813             # Make sure that we get a last message telling us we are done\n    814             elapsed_time = time.time() - self._start_time\n    815             self._print('Done %3i out of %3i | elapsed: %s finished',\n    816                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Mon Jun 20 14:36:37 2016\nPID: 4956               Python 2.7.11: C:\\Users\\schiang\\Anaconda\\python.exe\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.pyc in _parallel_helper(obj=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=209652396, splitter='best'), methodname='predict_proba', *args=(array([[  0.1675,   1.3608, ...,  10.    ,   2. ...7.8736, ...,   8.    ,   2.    ]], dtype=float32),), **kwargs={'check_input': False})\n    120     return tree\n    121 \n    122 \n    123 def _parallel_helper(obj, methodname, *args, **kwargs):\n    124     \"\"\"Private helper to workaround Python 2 pickle limitations\"\"\"\n--> 125     return getattr(obj, methodname)(*args, **kwargs)\n    126 \n    127 \n    128 class BaseForest(six.with_metaclass(ABCMeta, BaseEnsemble,\n    129                                     _LearntSelectorMixin)):\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\tree.pyc in predict_proba(self=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=209652396, splitter='best'), X=array([[  0.1675,   1.3608, ...,  10.    ,   2. ...7.8736, ...,   8.    ,   2.    ]], dtype=float32), check_input=False)\n    668             such arrays if n_outputs > 1.\n    669             The class probabilities of the input samples. The order of the\n    670             classes corresponds to that in the attribute `classes_`.\n    671         \"\"\"\n    672         X = self._validate_X_predict(X, check_input)\n--> 673         proba = self.tree_.predict(X)\n    674 \n    675         if self.n_outputs_ == 1:\n    676             proba = proba[:, :self.n_classes_]\n    677             normalizer = proba.sum(axis=1)[:, np.newaxis]\n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd in sklearn.tree._tree.Tree.predict (sklearn\\tree\\_tree.c:8449)()\n    731 \n    732 \n    733 \n    734 \n    735 \n--> 736 \n    737 \n    738 \n    739 \n    740 \n\n...........................................................................\nC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd in sklearn.tree._tree.Tree.predict (sklearn\\tree\\_tree.c:8321)()\n    733 \n    734 \n    735 \n    736 \n    737 \n--> 738 \n    739 \n    740 \n    741 \n    742 \n\nMemoryError: \n___________________________________________________________________________"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred while tokenizing input file C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (725, 0))\n",
      "\n",
      "An unexpected error occurred while tokenizing input file C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_tree.pyd\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (725, 0))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds['0_'], preds['1_'], preds['2_'] = zip(*preds.apply(lambda x: preds.columns[x.argsort()[::-1][:3]].tolist(), axis=1));\n",
    "preds = preds[['0_','1_','2_']];\n",
    "preds['row_id'] = X_test_labels\n",
    "preds['place_id'] = preds[['0_', '1_', '2_']].apply(lambda x: ' '.join([str(x1) for x1 in x]), axis=1)\n",
    "\n",
    "preds.drop('0_', axis=1, inplace=True)\n",
    "preds.drop('1_', axis=1, inplace=True)\n",
    "preds.drop('2_', axis=1, inplace=True)\n",
    "print 'writing to file'\n",
    "sub_file = os.path.join('rf_submission_' + str(datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")) + '.csv')\n",
    "preds.to_csv(sub_file,index=False)\n",
    "print 'finished'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
