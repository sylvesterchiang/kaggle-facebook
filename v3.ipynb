{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Partially based on grid_plus_classifier script:\n",
    "https://www.kaggle.com/svpons/facebook-v-predicting-check-ins/grid-knn/\n",
    "\n",
    "Additional features added: drop day, add mintue to hour, rough time estimation, border augmentation, float representation, change number of y grids to 20\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# Input varialbles\n",
    "#fw = [500., 1000., 4., 3., 2., 8.] #feature weights (black magic here)\n",
    "fw = [1, 1, 1, 1, 1, 1]\n",
    "th = 5 #Keeping place_ids with more than th samples.\n",
    "\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classification inside one grid cell.\n",
    "def process_one_cell(df_train, df_test, x_min, x_max, y_min, y_max):\n",
    "    x_border_augment = 0.02\n",
    "    y_border_augment = 0.02\n",
    "\n",
    "    #Working on df_train\n",
    "    df_cell_train = df_train[(df_train['x'] >= x_min-x_border_augment) & (df_train['x'] < x_max+x_border_augment) &\n",
    "                               (df_train['y'] >= y_min-y_border_augment) & (df_train['y'] < y_max+y_border_augment)]\n",
    "    #Records the number of occurrences of a place_id and masks the ones less than a certain threshold value\n",
    "    place_counts = df_cell_train.place_id.value_counts()\n",
    "    mask = (place_counts[df_cell_train.place_id.values] >= th).values\n",
    "    df_cell_train = df_cell_train.loc[mask]\n",
    "    \n",
    "    #Working on df_test\n",
    "    # to be delete: df_cell_test = df_test.loc[df_test.grid_cell == grid_id]\n",
    "    df_cell_test = df_test[(df_test['x'] >= x_min) & (df_test['x'] < x_max) &\n",
    "                               (df_test['y'] >= y_min) & (df_test['y'] < y_max)]\n",
    "    row_ids = df_cell_test.index\n",
    "\n",
    "    #Feature engineering on x and y\n",
    "    df_cell_train.loc[:,'x'] *= fw[0]\n",
    "    df_cell_train.loc[:,'y'] *= fw[1]\n",
    "    df_cell_test.loc[:,'x'] *= fw[0]\n",
    "    df_cell_test.loc[:,'y'] *= fw[1]\n",
    "    \n",
    "    #Preparing data\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df_cell_train.place_id.values)\n",
    "    X = df_cell_train.drop(['place_id'], axis=1).values.astype(float)\n",
    "    X_test = df_cell_test.values.astype(float)\n",
    "\n",
    "    #Applying the classifier\n",
    "    #clf = KNeighborsClassifier(n_neighbors=26, weights='distance', \n",
    "    #                           metric='manhattan', n_jobs=2)\n",
    "    clf = svm.SVC(kernel='rbf', max_iter=100, random_state=1234, probability=True)\n",
    "    \n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    pred_labels = le.inverse_transform(np.argsort(y_pred, axis=1)[:,::-1][:,:3]) \n",
    "    \n",
    "    return pred_labels, row_ids\n",
    "   \n",
    "   \n",
    "def process_grid(df_train, df_test, size, x_step, y_step):\n",
    "    \"\"\"\n",
    "    Iterates over all grid cells, aggregates the results and makes the\n",
    "    submission.\n",
    "    \"\"\" \n",
    "    preds = np.zeros((df_test.shape[0], 3), dtype=np.int64)\n",
    "    \n",
    "    for i in range((int)(size/x_step)):\n",
    "        start_time_row = time.time()\n",
    "        x_min = x_step * i\n",
    "        x_max = x_step * (i+1)\n",
    "        x_min = round(x_min, 4)\n",
    "        x_max = round(x_max, 4) \n",
    "        if x_max == size:\n",
    "            x_max = x_max + 0.001\n",
    "\n",
    "        for j in range((int)(size/y_step)):\n",
    "            y_min = y_step * j\n",
    "            y_max = y_step * (j+1)\n",
    "            y_min = round(y_min, 4)\n",
    "            y_max = round(y_max, 4)   \n",
    "            if y_max == size:\n",
    "                y_max = y_max + 0.001\n",
    "\n",
    "            #Applying classifier to one grid cell\n",
    "            pred_labels, row_ids = process_one_cell(df_train, df_test, x_min, x_max, y_min, y_max)\n",
    "\n",
    "            #Updating predictions\n",
    "            preds[row_ids] = pred_labels\n",
    "\n",
    "        print(\"Row %d/%d elapsed time: %.2f seconds\" % (i+1, (int)(size/x_step),(time.time() - start_time_row)))\n",
    "\n",
    "    print('Generating submission file ...')\n",
    "    #Auxiliary dataframe with the 3 best predictions for each sample\n",
    "    df_aux = pd.DataFrame(preds, dtype=str, columns=['l1', 'l2', 'l3'])  \n",
    "    \n",
    "    #Concatenating the 3 predictions for each sample\n",
    "    ds_sub = df_aux.l1.str.cat([df_aux.l2, df_aux.l3], sep=' ')\n",
    "    \n",
    "    #Writting to csv\n",
    "    ds_sub.name = 'place_id'\n",
    "    ds_sub.to_csv('sub_knn.csv', index=True, header=True, index_label='row_id')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Preparing train data\n",
      "Preparing test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:224: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-410f59d09d90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;31m#Solving classification problems inside each grid cell\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mprocess_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-3172125cdff1>\u001b[0m in \u001b[0;36mprocess_grid\u001b[1;34m(df_train, df_test, size, x_step, y_step)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m#Applying classifier to one grid cell\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[0mpred_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_one_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[1;31m#Updating predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-3172125cdff1>\u001b[0m in \u001b[0;36mprocess_one_cell\u001b[1;34m(df_train, df_test, x_min, x_max, y_min, y_max)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mpred_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    608\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m         \"\"\"\n\u001b[1;32m--> 610\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_proba\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\schiang\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.pyc\u001b[0m in \u001b[0;36m_check_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m             raise AttributeError(\"predict_proba is not available when \"\n\u001b[0m\u001b[0;32m    578\u001b[0m                                  \" probability=False\")\n\u001b[0;32m    579\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_impl\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'c_svc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'nu_svc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "# Main\n",
    "if __name__ == '__main__':\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    print('Loading data ...')\n",
    "    df_train = pd.read_csv('data/train.csv',\n",
    "                           usecols=['row_id','x','y','time','place_id'], \n",
    "                           index_col = 0)\n",
    "    df_test = pd.read_csv('data/test.csv',\n",
    "                          usecols=['row_id','x','y','time'],\n",
    "                          index_col = 0)\n",
    " \n",
    "    #Defining the size of the grid\n",
    "    size = 10.0\n",
    "    x_step = 0.5\n",
    "    y_step = 0.5\n",
    "    \n",
    "    print('Preparing train data')\n",
    "    #Feature engineering\n",
    "    minute = df_train['time']%60\n",
    "    df_train['hour'] = df_train['time']//60\n",
    "    df_train['weekday'] = df_train['hour']//24\n",
    "    df_train['month'] = df_train['weekday']//30\n",
    "    df_train['year'] = (df_train['weekday']//365+1)*fw[5]\n",
    "    df_train['hour'] = ((df_train['hour']%24+1)+minute/60.0)*fw[2]\n",
    "    df_train['weekday'] = (df_train['weekday']%7+1)*fw[3]\n",
    "    df_train['month'] = (df_train['month']%12+1)*fw[4]\n",
    "    df_train.drop(['time'], axis=1, inplace=True)\n",
    "    \n",
    "    print('Preparing test data')\n",
    "    minute = df_test['time']%60\n",
    "    df_test['hour'] = df_test['time']//60\n",
    "    df_test['weekday'] = df_test['hour']//24\n",
    "    df_test['month'] = df_test['weekday']//30\n",
    "    df_test['year'] = (df_test['weekday']//365+1)*fw[5]\n",
    "    df_test['hour'] = ((df_test['hour']%24+1)+minute/60.0)*fw[2]\n",
    "    df_test['weekday'] = (df_test['weekday']%7+1)*fw[3]\n",
    "    df_test['month'] = (df_test['month']%12+1)*fw[4]\n",
    "    df_test.drop(['time'], axis=1, inplace=True)\n",
    "    \n",
    "    #Solving classification problems inside each grid cell \n",
    "    process_grid(df_train, df_test, size, x_step, y_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
